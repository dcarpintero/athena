title = "Athena Prompt Templates for Cohere's API"

[abstract]
prompt =    """
            You are a proficient assistant in Natural Language Processing (NLP). You will be given the abstract of a research paper.
            Your task is to enrich technical Named Entities with Wikipedia links as outlined in the Enriched_Text section of the EXAMPLE.
            Focus on Named Entities that are relevant to the fields of Artificial Intelligence (AI), Machine Learning (ML), Algorithms, Natural Language Processing, and Computer Science. 
            This enrichment aims to provide comprehensive, linked contextual information for each technical term, enhancing the reader's understanding and access to further resources.

            EXAMPLE:
            Text: 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. 
            Unlike recent language representation models, BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly 
            conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional
            output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial
            task specific architecture modifications.'

            Enriched_Text: 
            ['We introduce a new language representation model called [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)), 
            which stands for [Bidirectional Encoder Representations from Transformers](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)). 
            Unlike recent language representation models, BERT is designed to pretrain deep bidirectional representations from unlabeled text by jointly 
            conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be finetuned with just one additional 
            output layer to create state-of-the-art models for a wide range of tasks, such as [question answering](https://en.wikipedia.org/wiki/Question_answering) 
            and [language inference](https://en.wikipedia.org/wiki/Natural_language_inference), without substantial task-specific architecture modifications.']
            --

            TASK:
            Text: {text}
            """

[tweet]
prompt =    """
            Write an engaging and informative tweet about a research paper. The research paper delves into '{summary}', exploring groundbreaking insights 
            and findings. Your tweet should capture the essence of the paper in a way that resonates with a broad audience, sparking interest and curiosity. 
            Include relevant hashtags that are relevant to the field related to the paper's topic. Additionally, incorporate this link {link} to direct 
            readers to the full research paper. Structure your response as a JSON dictionary, following this example template:
    
            EXAMPLE:
            {{
                "text" : "Exploring AI's language frontiers with 'BERT: Pre-training of Deep Bidirectional Transformers' by Devlin et al. (2018). \
                          BERT revolutionizes NLP with state-of-the-art results across various tasks. \
                          Read more: https://arxiv.org/abs/1810.04805 #AI #NLP #MachineLearning ðŸ¤–ðŸ’¬",
            }} 
            
            ---
            """

[email]
prompt =    """
            Create a JSON-formatted response for a professional cold email. The email is from myself, {sender}, a researcher at {institution}, \
            addressed to {receivers}, authors of the research paper '{title}'. The email should express respect for their work, \
            briefly introduce my research interests, and inquire about their willingness to collaborate on an upcoming project that aligns with our mutual interests.

            EXAMPLE:
            {{
                "subject" : "Collaboration on {topic} with {institution}"
                "body" : "Dear {receivers},\n\nI hope this message finds you well. My name is {sender}, and I'm a researcher specializing in {topic} at {institution}. \ 
                          After reading your influential paper, '{topic}', I was deeply impressed by your insights and findings. And I am reaching out to explore the \
                          possibility of collaborating on a project that I believe could benefit greatly from your expertise. I would be honored to discuss this further \
                          if you are interested.\n\nLooking forward to the possibility of working together.\n\nBest regards,\n{sender}"
            }}

            ---
            """

[keywords]
prompt =    """
            You are a helpful research assistant that will be given a research paper. Your task is to analyze the paper and to identify the most relevant keywords that 
            capture the core concepts and technologies discussed. For each keyword, provide a brief explanation of its significance in the context of this research. 
            Focus on terms related to the paper's primary field, including any specific methodologies, technologies, theories, or applications mentioned. 
            Your explanations should help in understanding the abstract's main contributions and the implications of the research in its respective field.

            EXAMPLE:
            Text: 'The recent advancements in Natural Language Processing (NLP) have been significantly influenced by the introduction of Transformer models. 
            These models have revolutionized the way machines understand and generate human language. This paper explores the development and application of Transformer 
            models in various NLP tasks such as machine translation, text summarization, and sentiment analysis. We discuss the underlying architecture of the Transformer,
            focusing on its unique self-attention mechanism, which allows the model to weigh the importance of different words in a sentence. The paper also examines the 
            implications of Transformers on future NLP research and their potential to create more human-like AI language systems.'

            keywords: 
            {
                "Transformers": "A type of model architecture in AI that has significantly improved the performance of NLP tasks. It is known for its efficiency in processing sequences of data.",
                "Natural Language Processing": "The field of study that focuses on the interaction between computers and human languages. It involves teaching machines to understand and respond to human text or voice.",
                "Machine Translation": "An application of NLP where the goal is to automatically translate text or speech from one language to another using machines.",
                "Text Summarization": "An NLP task where the objective is to condense a larger body of text into a concise summary while retaining key information and meaning.",
                "Sentiment Analysis": "An NLP process of computationally identifying and categorizing opinions expressed in a piece of text to determine the writer's attitude towards a particular topic.",
                "Self-Attention Mechanism": "A feature of Transformer models that allows the model to focus on different parts of the input sequence, crucial for understanding the context and relationships within the text."
            }
            
            ---
            
            TASK:
            Text: {text}
            """